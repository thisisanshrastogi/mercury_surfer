{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a87a0fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim import corpora\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "import gensim\n",
    "import pyLDAvis.gensim_models\n",
    "import pyLDAvis\n",
    "from tqdm import tqdm\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26bc25de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6859/6859 [00:00<00:00, 111312.99it/s]\n",
      "100%|██████████| 6859/6859 [00:00<00:00, 169254.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['like', 'app'], ['nice_idea', 'terrible', 'execution', 'people', 'bot', 'bot', 'say', 'person', 'answer', 'hour', 'one', 'ever', 'automate_response', 'rent', 'due', 'day', 'access', 'money', 'stick', 'help', 'face', 'possible', 'eviction', 'thank', 'cleo'], ['awful', 'user_interface'], ['similar', 'functionality', 'design', 'mint', 'connection_issue', 'data', 'problem', 'discover', 'monarch', 'look', 'replacement_mint', 'mint', 'certainly', 'perfect', 'free', 'perform', 'well', 'monarch', 'much', 'functionality', 'similar', 'design', 'issue', 'monach', 'connect', 'account', 'disappointing', 'consider_cost', 'monarch', 'mint', 'free'], ['year', 'still', 'android_widget']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(\"./sentiment_classified_2.csv\")\n",
    "\n",
    "def clean_more(text):\n",
    "    text = text.lower()\n",
    "    return text.split()\n",
    "\n",
    "df = df[df['Stars'] !=5].reset_index(drop=True)\n",
    "df['Cleaned Reviews'] = df['Cleaned Reviews'].fillna('')\n",
    "df['Cleaned Reviews'] = df['Cleaned Reviews']\n",
    "df['tokens'] = df[\"Cleaned Reviews\"].progress_apply(clean_more)\n",
    "\n",
    "bigram_phrases = Phrases(df['tokens'],min_count=5,threshold=5)\n",
    "\n",
    "bigram_mod = Phraser(bigram_phrases)\n",
    "\n",
    "df['bigram_tokens'] = df['tokens'].progress_apply(lambda doc: bigram_mod[doc])\n",
    "\n",
    "print(df['bigram_tokens'].sample(5).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d825b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dictionary = corpora.Dictionary(df['bigram_tokens'])\n",
    "\n",
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=5000)\n",
    "\n",
    "corpus = [dictionary.doc2bow(doc) for doc in df['bigram_tokens']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d7ca17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_coherence_values(dictionary, corpus, texts, start=5, limit=20, step=1):\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit + 1, step):\n",
    "        model = LdaMulticore(\n",
    "            corpus=corpus,\n",
    "            id2word=dictionary,\n",
    "            num_topics=num_topics,\n",
    "            passes=15,\n",
    "            workers=6,\n",
    "            random_state=42\n",
    "        )\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_score = coherencemodel.get_coherence()\n",
    "        coherence_values.append(coherence_score)\n",
    "        print(f'Number of topics: {num_topics}, Coherence Score: {coherence_score:.4f}')\n",
    "    return model_list, coherence_values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63b4efff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of topics: 5, Coherence Score: 0.5231\n",
      "Number of topics: 6, Coherence Score: 0.5259\n",
      "Number of topics: 7, Coherence Score: 0.5261\n",
      "Number of topics: 8, Coherence Score: 0.5507\n",
      "Number of topics: 9, Coherence Score: 0.5472\n",
      "Number of topics: 10, Coherence Score: 0.5292\n",
      "Number of topics: 11, Coherence Score: 0.5420\n",
      "Number of topics: 12, Coherence Score: 0.5270\n",
      "Number of topics: 13, Coherence Score: 0.5228\n",
      "Number of topics: 14, Coherence Score: 0.5233\n",
      "Number of topics: 15, Coherence Score: 0.5139\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_list, coherence_values = compute_coherence_values(dictionary, corpus, df['bigram_tokens'], start=5, limit=15, step=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a953bef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = model_list[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "914c0a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_data = []\n",
    "for num_topics, model in zip(range(5, 16), model_list):\n",
    "    for idx, topic in model.print_topics(num_topics=num_topics, num_words=8):\n",
    "        topics_data.append({\n",
    "            \"Model_Num_Topics\": num_topics,\n",
    "            \"Topic_Index\": idx,\n",
    "            \"Topic_Terms\": topic\n",
    "        })\n",
    "\n",
    "topics_df = pd.DataFrame(topics_data)\n",
    "topics_df.to_csv(\"LDA_topics_by_model.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "539aebf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a document-topic distribution matrix\n",
    "doc_topic_dists = []\n",
    "\n",
    "for doc in corpus:\n",
    "    topic_probs = best_model.get_document_topics(doc, minimum_probability=0)\n",
    "    doc_topic_dists.append([prob for _, prob in topic_probs])\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_topic_dist = pd.DataFrame(doc_topic_dists)\n",
    "df_topic_dist.columns = [f'Topic {i}' for i in range(df_topic_dist.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d6cee99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Count per Dominant Topic:\n",
      "Topic 0     510\n",
      "Topic 1     465\n",
      "Topic 10    449\n",
      "Topic 11    689\n",
      "Topic 12    770\n",
      "Topic 2     381\n",
      "Topic 3     402\n",
      "Topic 4     451\n",
      "Topic 5     395\n",
      "Topic 6     680\n",
      "Topic 7     607\n",
      "Topic 8     516\n",
      "Topic 9     544\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Find dominant topic in each document\n",
    "dominant_topics = df_topic_dist.idxmax(axis=1)\n",
    "dominant_topic_counts = dominant_topics.value_counts().sort_index()\n",
    "\n",
    "# Print count of documents dominated by each topic\n",
    "print(\"Document Count per Dominant Topic:\")\n",
    "print(dominant_topic_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f000313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Share of Each Topic:\n",
      "Topic 12    0.109934\n",
      "Topic 6     0.095110\n",
      "Topic 11    0.095068\n",
      "Topic 7     0.083230\n",
      "Topic 9     0.080527\n",
      "Topic 8     0.075395\n",
      "Topic 1     0.070197\n",
      "Topic 4     0.069955\n",
      "Topic 10    0.069043\n",
      "Topic 0     0.064961\n",
      "Topic 5     0.064046\n",
      "Topic 3     0.061679\n",
      "Topic 2     0.060854\n",
      "dtype: float32\n"
     ]
    }
   ],
   "source": [
    "topic_shares = df_topic_dist.mean().sort_values(ascending=False)\n",
    "\n",
    "print(\"\\nAverage Share of Each Topic:\")\n",
    "print(topic_shares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4334c05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic Summary:\n",
      "          Dominant Doc Count  Average Share\n",
      "Topic 12                 770       0.109934\n",
      "Topic 11                 689       0.095068\n",
      "Topic 6                  680       0.095110\n",
      "Topic 7                  607       0.083230\n",
      "Topic 9                  544       0.080527\n",
      "Topic 8                  516       0.075395\n",
      "Topic 0                  510       0.064961\n",
      "Topic 1                  465       0.070197\n",
      "Topic 4                  451       0.069955\n",
      "Topic 10                 449       0.069043\n",
      "Topic 3                  402       0.061679\n",
      "Topic 5                  395       0.064046\n",
      "Topic 2                  381       0.060854\n"
     ]
    }
   ],
   "source": [
    "summary_df = pd.DataFrame({\n",
    "    \"Dominant Doc Count\": dominant_topic_counts,\n",
    "    \"Average Share\": df_topic_dist.mean()\n",
    "}).fillna(0)\n",
    "\n",
    "summary_df = summary_df.sort_values(\"Dominant Doc Count\", ascending=False)\n",
    "print(\"\\nTopic Summary:\")\n",
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "462878ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df.to_csv(\"LDA_quantitative.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b466f8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Values:\n",
      "Number of Topics: 5, Coherence Score: 0.5231\n",
      "Number of Topics: 6, Coherence Score: 0.5259\n",
      "Number of Topics: 7, Coherence Score: 0.5261\n",
      "Number of Topics: 8, Coherence Score: 0.5507\n",
      "Number of Topics: 9, Coherence Score: 0.5472\n",
      "Number of Topics: 10, Coherence Score: 0.5292\n",
      "Number of Topics: 11, Coherence Score: 0.5420\n",
      "Number of Topics: 12, Coherence Score: 0.5270\n",
      "Number of Topics: 13, Coherence Score: 0.5228\n",
      "Number of Topics: 14, Coherence Score: 0.5233\n",
      "Number of Topics: 15, Coherence Score: 0.5139\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCoherence Values:\")\n",
    "for num_topics, coherence in zip(range(5, 16), coherence_values):\n",
    "    print(f\"Number of Topics: {num_topics}, Coherence Score: {coherence:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
